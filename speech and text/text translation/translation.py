# -*- coding: utf-8 -*-
"""translation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fILQNfTv2ePGsStoUjAPf_Hdd_0PN0Lq
"""

!pip install googletrans==4.0.0-rc1

from googletrans import Translator

# Create a Translator object
translator = Translator()

# Text to be translated
text_to_translate = "Hello, how are you?"

# Translate the text to a target language
target_language = "ar"  # Change to the desired target language code
translated_text = translator.translate(text_to_translate, dest=target_language)

# Print the translation result
print("Original Text:", text_to_translate)
print("Translated Text:", translated_text.text)
print("Detected Source Language:", translated_text.src)
print("Target Language:", translated_text.dest)

!pip install transformers

!pip install sentencepiece

from transformers import MarianMTModel, MarianTokenizer

def translate(text, target_language):
    model_name = f'Helsinki-NLP/opus-mt-en-{target_language}'
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)

    inputs = tokenizer.encode(text, return_tensors="pt")
    outputs = model.generate(inputs, num_beams=4, max_length=50, early_stopping=True)
    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return translated_text

input_text = "Hello, how are you?"
target_language = 'ar'
translated_text = translate(input_text, target_language)
print(translated_text)

!pip install transformers

!pip install sentencepiece

!pip install sentencepiece

from transformers import MarianMTModel, MarianTokenizer

# Replace 'Helsinki-NLP/opus-mt-en-de' with the model of your choice
model_name = 'Helsinki-NLP/opus-mt-en-ar'
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)

source_sentence = "Hello, how are you?"
input_ids = tokenizer.encode(source_sentence, return_tensors="pt")
translated_ids = model.generate(input_ids)
translated_sentence = tokenizer.decode(translated_ids[0], skip_special_tokens=True)
print("Translated:", translated_sentence)





