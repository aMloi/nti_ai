# -*- coding: utf-8 -*-
"""all algorithms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p4NlFhzUvadtMn0EZbQpR7xlRuTpjL5M
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier

dataset = pd.read_csv('diabetes3.csv')

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=0,strategy="mean")
imputer=imputer.fit(x[:,1:7])
x[:,1:7]=imputer.transform(x[:,1:7])

x = dataset.iloc[:,0:8].values

y=dataset.iloc[:,8].values

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30)

from sklearn.preprocessing import StandardScaler

sm = StandardScaler()

x_train=sm.fit_transform(x_train)

x_test=sm.transform(x_test)

cam= DecisionTreeClassifier(criterion='entropy')
sm = StandardScaler()

x_train=sm.fit_transform(x_train)
x_test=sm.transform(x_test)


cam.fit(x_train,y_train)

y_pred = cam.predict(x_test)

from sklearn.metrics import confusion_matrix

cm= confusion_matrix(y_test,y_pred)

accuracy=0
percision=0
recall=0

accuracy = ((cm[0][0] + cm[1][1]) / len(y_test)) * 100
precision = cm[0][0] / (cm[0][0] + cm[0][1])*100
recall = cm[0][0] / (cm[0][0] + cm[1][0])*100

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)

from sklearn.ensemble import RandomForestClassifier
cam= RandomForestClassifier( n_estimators=5,   criterion='entropy',random_state=0)
cam.fit(x_train,y_train)
y_pred = cam.predict(x_test)
from sklearn.metrics import confusion_matrix

cm= confusion_matrix(y_test,y_pred)

accuracy=0
percision=0
recall=0

accuracy = ((cm[0][0] + cm[1][1]) / len(y_test)) * 100
precision = cm[0][0] / (cm[0][0] + cm[0][1])*100
recall = cm[0][0] / (cm[0][0] + cm[1][0])*100

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)

from sklearn.svm import SVC
clas = SVC(kernel='linear',random_state=10)

clas.fit(x_train,y_train)

y_pred=clas.predict(x_test)
from sklearn.metrics import confusion_matrix

cm= confusion_matrix(y_test,y_pred)

accuracy=0
percision=0
recall=0

accuracy = ((cm[0][0] + cm[1][1]) / len(y_test)) * 100
precision = cm[0][0] / (cm[0][0] + cm[0][1])*100
recall = cm[0][0] / (cm[0][0] + cm[1][0])*100

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5)#K
classifier.fit(x_train, y_train)
y_pred = classifier.predict(x_test)
from sklearn.metrics import confusion_matrix

cm= confusion_matrix(y_test,y_pred)

accuracy=0
percision=0
recall=0

accuracy = ((cm[0][0] + cm[1][1]) / len(y_test)) * 100
precision = cm[0][0] / (cm[0][0] + cm[0][1])*100
recall = cm[0][0] / (cm[0][0] + cm[1][0])*100

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)

from sklearn.linear_model import LogisticRegression

rg = LogisticRegression()

rg.fit(x_train,y_train)

y_pred = rg.predict(x_test)


cm= confusion_matrix(y_test,y_pred)

accuracy=0
percision=0
recall=0

accuracy = ((cm[0][0] + cm[1][1]) / len(y_test)) * 100
precision = cm[0][0] / (cm[0][0] + cm[0][1])*100
recall = cm[0][0] / (cm[0][0] + cm[1][0])*100

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)